# -*- coding: utf-8 -*-
"""Data exploration

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pr8ecHmesLAY52p7yGriuqx1AcFX7X-k

# Data exploration

The dataset used for this project is the one published in the "[Challenges in Representation Learning: Facial Expression Recognition Challenge](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data)" by Kaggle.

> **"Challenges in Representation Learning: A report on three machine learning contests."** I. Goodfellow, D. Erhan, P. L. Carrier, A. Courville, M. Mirza, B. Hamner, W. Cukierski, Y. Tang, D. H. Lee, Y. Zhou, C. Ramaiah, F. Feng, R. Li, X. Wang, D. Athanasakis, J. Shawe-Taylor, M. Milakov, J. Park, R. Ionescu, M. Popescu, C. Grozea, J. Bergstra, J. Xie, L. Romaszko, B. Xu, Z. Chuang, and Y. Bengio. arXiv 2013.

### Data description (as detailed by Kaggle)

The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).

The csv file contains two main columns, "emotion" and "pixels". The "emotion" column contains a numeric code ranging from 0 to 6, inclusive, for the emotion that is present in the image. The "pixels" column contains a string surrounded in quotes for each image. The contents of this string a space-separated pixel values in row major order. test.csv contains only the "pixels" column and your task is to predict the emotion column.

This dataset was prepared by Pierre-Luc Carrier and Aaron Courville, as part of an ongoing research project. They have graciously provided the workshop organizers with a preliminary version of their dataset to use for this contest.

## Getting the data 

We can directly download the dataset from Kaggle using the Kaggle API:
"""

# Update Kaggle API:
!pip install --upgrade -q kaggle

# Create a new folder for Kaggle config file:
!mkdir /root/.kaggle

import json

token = {
    "username": "vaanirawat",
    "key": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
}

with open('/root/.kaggle/kaggle.json', 'w') as config_file:
    json.dump(token, config_file)

# Provide access to Kaggle config file:
!chmod 600 /root/.kaggle/kaggle.json

!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge

"""We can now proceed to extract our dataset from the compressed file."""

!tar -xvf "fer2013.tar.gz"

"""Once the files are extracted, we can proceed to explore the dataset.

## Exploring the dataset

We are going to use the Pandas Python library in order to explore a bit the structure of the dataset and its contents.


First of all we load our dataset and print the head of it.
"""

import pandas as pd

df = pd.read_csv('fer2013/fer2013.csv')
df.head()

"""We can also get a general description of the dataset:"""

df.describe()

"""An interesting thing that happens is that this dataset has images used for three different purposes:

- Training
- Private testing
- Public testing
"""

df['Usage'].value_counts()

"""We need to access the data information from the dataframe so we can iterate later for each element."""

# Set image index:
img_index = 2
ith_face = df[['pixels']].iloc[img_index]
ith_face = ith_face.values[0]
ith_face

"""If we want to load a specific picture, we are going to convert the data string into a Numpy array in order to plot it using matplotlib."""

import numpy as np

data = np.fromstring(ith_face, dtype=int, sep=' ')
data = np.reshape(data, (48, 48))
data

"""Now we are able to plot the loaded image:"""

import matplotlib.pyplot as plt
plt.style.use('ggplot')

plt.imshow(data, cmap='gray')
plt.axis('off')

"""## Packing functionality

Now that we have explored a bit the dataset and we are able to load a single image, we proceed to create functions that will allow us to load the full dataset as numpy arrays in order to feed a neural network.
"""

def load_dataset():
    """Utility function to load the FER2013 dataset.
    
    It returns the formated tuples (X_train, y_train) , (X_test, y_test).
    """

    # Load and filter in Training/not Training data:
    df = pd.read_csv('fer2013/fer2013.csv')
    training = df.loc[df['Usage'] == 'Training']
    testing = df.loc[df['Usage'] != 'Training']

    # X_train values:
    X_train = training[['pixels']].values
    X_train = [np.fromstring(item[0], dtype=int, sep=' ') for item in X_train]
    X_train = [item.reshape((48, 48)) for item in X_train]
    X_train = np.array(X_train)

    # X_test values:
    X_test = testing[['pixels']].values
    X_test = [np.fromstring(item[0], dtype=int, sep=' ') for item in X_test]
    X_test = [item.reshape((48, 48)) for item in X_test]
    X_test = np.array(X_test)

    # y_train, y_test values:
    y_train = training[['emotion']].values
    y_test = testing[['emotion']].values

    return (X_train, y_train) , (X_test, y_test)

"""We can now directly load the complete dataset splitted into training and testing data."""

(X_train, y_train) , (X_test, y_test) = load_dataset()

"""This dataset loading is consistent so we can use images directly:"""

plt.imshow(X_train[2], cmap='gray')
plt.axis('off')

